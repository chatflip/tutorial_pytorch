{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pruning\n",
    "https://pytorch.org/tutorials/intermediate/pruning_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.nn.utils.prune as prune\n",
    "\n",
    "sys.path.append(\"../1-classification_mnist/py\")\n",
    "from model import LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LeNet()\n",
    "print(list(model.features[0].named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local Pruinig (モジュール単位)\n",
    "## featuresの1層目のweightと名前がついてるnn.moduleのweightを30%ランダムに枝刈りする設定\n",
    "prune.random_unstructured(model.features[0], name=\"weight\", amount=0.4)\n",
    "\n",
    "## 枝刈りするパラメータがweightからweight_origになる\n",
    "print(list(model.features[0].named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## buffersにmaskが格納される(mask=0)\n",
    "print(list(model.features[0].named_buffers()))\n",
    "## modelのweightには, maskが適用された値が格納される\n",
    "print(model.features[0].weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forwardは枝刈りしたほうのweightが使われる\n",
    "print(model.features[0]._forward_pre_hooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## featuresの1層目のbiasと名前がついてるnn.moduleのbiasのL1normが最小の2個で枝刈りする設定\n",
    "prune.l1_unstructured(model.features[0], name=\"bias\", amount=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(model.features[0].named_buffers()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"before remove\")\n",
    "print(list(model.features[0].named_parameters()))\n",
    "# name+'orig'とname+'_mask'を削除してweightを枝刈り前と同じstate_dictの状態にする\n",
    "prune.remove(model.features[0], 'weight')\n",
    "print(\"after remove\")\n",
    "print(list(model.features[0].named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_name = \"./../1-classification_mnist/weight/MNIST_lenet_10.pth\"\n",
    "print(\"use pretrained model : %s\" % weight_name)\n",
    "param = torch.load(weight_name, map_location=lambda storage, loc: storage)\n",
    "model = LeNet()\n",
    "model.load_state_dict(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, module in model.named_modules():\n",
    "    # prune 20% of connections in all 2D-conv layers\n",
    "    if isinstance(module, torch.nn.Conv2d):\n",
    "        prune.l1_unstructured(module, name='weight', amount=0.4)\n",
    "    # prune 40% of connections in all linear layers\n",
    "    elif isinstance(module, torch.nn.Linear):\n",
    "        prune.l1_unstructured(module, name='weight', amount=0.4)\n",
    "print(dict(model.named_buffers()).keys())\n",
    "\n",
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, torch.nn.Conv2d):\n",
    "        prune.remove(module, 'weight')\n",
    "    elif isinstance(module, torch.nn.Linear):\n",
    "        prune.remove(module, 'weight')\n",
    "torch.save(model.state_dict(), 'weight/MNIST_lenet_10_local_pruning.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Pruning (ネットワーク全体)\n",
    "weight_name = \"./../1-classification_mnist/weight/MNIST_lenet_10.pth\"\n",
    "print(\"use pretrained model : %s\" % weight_name)\n",
    "param = torch.load(weight_name, map_location=lambda storage, loc: storage)\n",
    "model = LeNet()\n",
    "model.load_state_dict(param)\n",
    "\n",
    "parameters_to_prune = []\n",
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, torch.nn.Conv2d):\n",
    "        parameters_to_prune.append((module, 'weight'))\n",
    "    elif isinstance(module, torch.nn.Linear):\n",
    "        parameters_to_prune.append((module, 'weight'))\n",
    "parameters_to_prune = tuple(parameters_to_prune)\n",
    "\n",
    "print(parameters_to_prune)\n",
    "\n",
    "# ネットワーク全体でL1normが小さい順に20%枝刈り \n",
    "prune.global_unstructured(\n",
    "    parameters_to_prune,\n",
    "    pruning_method=prune.L1Unstructured,\n",
    "    amount=0.4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sparsity in features[0].weight: {:.2f}%\".format(\n",
    "        100. * float(torch.sum(model.features[0].weight == 0))\n",
    "        / float(model.features[0].weight.nelement())))\n",
    "print(\"Sparsity in features[3].weight: {:.2f}%\".format(\n",
    "        100. * float(torch.sum(model.features[3].weight == 0))\n",
    "        / float(model.features[3].weight.nelement())))\n",
    "print(\"Sparsity in classifier[0].weight: {:.2f}%\".format(\n",
    "        100. * float(torch.sum(model.classifier[0].weight == 0))\n",
    "        / float(model.classifier[0].weight.nelement())))\n",
    "print(\"Sparsity in classifier[2].weight: {:.2f}%\".format(\n",
    "        100. * float(torch.sum(model.classifier[2].weight == 0))\n",
    "        / float(model.classifier[2].weight.nelement())))\n",
    "print(\"Sparsity in classifier[4].weight: {:.2f}%\".format(\n",
    "        100. * float(torch.sum(model.classifier[4].weight == 0))\n",
    "        / float(model.classifier[4].weight.nelement())))\n",
    "\n",
    "print(\"Global sparsity: {:.2f}%\".format(\n",
    "        100. * float(torch.sum(model.features[0].weight == 0)\n",
    "            + torch.sum(model.features[3].weight == 0)\n",
    "            + torch.sum(model.classifier[0].weight == 0)\n",
    "            + torch.sum(model.classifier[2].weight == 0)\n",
    "            + torch.sum(model.classifier[4].weight == 0))\n",
    "        / float(model.features[0].weight.nelement()\n",
    "            + model.features[3].weight.nelement()\n",
    "            + model.classifier[0].weight.nelement()\n",
    "            + model.classifier[2].weight.nelement()\n",
    "            + model.classifier[4].weight.nelement())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, torch.nn.Conv2d):\n",
    "        prune.remove(module, 'weight')\n",
    "    elif isinstance(module, torch.nn.Linear):\n",
    "        prune.remove(module, 'weight')\n",
    "torch.save(model.state_dict(), 'weight/MNIST_lenet_10_global_pruning.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate Acuracy  \n",
    "cd ./../1-classification_mnist  \n",
    "python py/main.py --evaluate --resume='weight/MNIST_lenet_10.pth'  \n",
    "python py/main.py --evaluate --resume='./../notebook/weight/MNIST_lenet_10_local_pruning.pth'  \n",
    "python py/main.py --evaluate --resume='./../notebook/weight/MNIST_lenet_10_global_pruning.pth'  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python py/main.py --evaluate --resume='weight/MNIST_lenet_10.pth'  \n",
    "use pretrained model : weight/MNIST_lenet_10.pth  \n",
    "Validate: [10/10] Time  0.081 ( 0.205)    Data  0.001 ( 0.108)    Loss 0.03638 (0.03311)  Acc@1  98.80 ( 98.92)   Acc@5 100.00 ( 99.99)  \n",
    "python py/main.py --evaluate --resume='./../notebook/weight/MNIST_lenet_10_local_pruning.pth'  \n",
    "use pretrained model : ./../notebook/weight/MNIST_lenet_10_local_pruning.pth  \n",
    "Validate: [10/10] Time  0.080 ( 0.186)    Data  0.001 ( 0.086)    Loss 0.03094 (0.03337)  Acc@1  98.90 ( 98.95)   Acc@5 100.00 ( 99.99)  \n",
    "python py/main.py --evaluate --resume='./../notebook/weight/MNIST_lenet_10_global_pruning.pth'  \n",
    "use pretrained model : ./../notebook/weight/MNIST_lenet_10_global_pruning.pth  \n",
    "Validate: [10/10] Time  0.087 ( 0.180)    Data  0.001 ( 0.082)    Loss 0.03372 (0.03378)  Acc@1  98.90 ( 98.94)   Acc@5 100.00 ( 99.99)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt14",
   "language": "python",
   "name": "pt14"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
