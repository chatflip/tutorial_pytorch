{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pruning  \n",
    "https://pytorch.org/tutorials/intermediate/pruning_tutorial.html  \n",
    "枝刈りの種類  \n",
    "Untructured Pruinig  \n",
    "- prune.l1_unstructured: tensor単位の枝刈り  \n",
    "\n",
    "Structured Pruinig   \n",
    "- prune.ln_structured: channel単位の枝刈り  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.nn.utils.prune as prune\n",
    "\n",
    "sys.path.append(\"../1-classification_mnist/py\")\n",
    "from model import LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LeNet()\n",
    "print(list(model.features[0].named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pruningの基本\n",
    "## featuresの1層目のweightと名前がついてるnn.moduleのweightを30%ランダムに枝刈りする設定\n",
    "prune.random_unstructured(model.features[0], name=\"weight\", amount=0.4)\n",
    "\n",
    "## 枝刈りするパラメータがweightからweight_origになる\n",
    "print(list(model.features[0].named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## buffersにmaskが格納される(mask=0)\n",
    "print(list(model.features[0].named_buffers()))\n",
    "## modelのweightには, maskが適用された値が格納される\n",
    "print(model.features[0].weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forwardは枝刈りしたほうのweightが使われる\n",
    "print(model.features[0]._forward_pre_hooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## featuresの1層目のbiasと名前がついてるnn.moduleのbiasのL1normが最小の2個で枝刈りする設定\n",
    "prune.l1_unstructured(model.features[0], name=\"bias\", amount=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(model.features[0].named_buffers()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"before remove\")\n",
    "print(list(model.features[0].named_parameters()))\n",
    "# name+'orig'とname+'_mask'を削除してweightを枝刈り前と同じstate_dictの状態にする\n",
    "prune.remove(model.features[0], 'weight')\n",
    "print(\"after remove\")\n",
    "print(list(model.features[0].named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Structured Pruinig (モジュール単位)\n",
    "weight_name = \"./../1-classification_mnist/weight/MNIST_lenet_10.pth\"\n",
    "print(\"use pretrained model : %s\" % weight_name)\n",
    "param = torch.load(weight_name, map_location=lambda storage, loc: storage)\n",
    "model = LeNet()\n",
    "model.load_state_dict(param)\n",
    "\n",
    "is_first_conv = True\n",
    "prune_amount = 0.4\n",
    "for name, module in model.named_modules():\n",
    "    # prune 40% of connections in all 2D-conv layers\n",
    "    if isinstance(module, torch.nn.Conv2d):\n",
    "        if is_first_conv:\n",
    "            is_first_conv = False\n",
    "        else:\n",
    "            prune.ln_structured(module, name='weight', amount=prune_amount, n=2, dim=1)\n",
    "    # prune 40% of connections in all linear layers\n",
    "    elif isinstance(module, torch.nn.Linear):\n",
    "        prune.ln_structured(module, name='weight', amount=prune_amount, n=2, dim=1)\n",
    "print(dict(model.named_buffers()).keys())\n",
    "\n",
    "is_first_conv = True  # 50%超えると入力のweightを全部枝刈りするから\n",
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, torch.nn.Conv2d):\n",
    "        if is_first_conv:\n",
    "            is_first_conv = False\n",
    "        else:\n",
    "            prune.remove(module, 'weight')\n",
    "    elif isinstance(module, torch.nn.Linear):\n",
    "        prune.remove(module, 'weight')\n",
    "torch.save(model.state_dict(), 'weight/MNIST_lenet_10_structured_pruning.pth')\n",
    "\n",
    "import itertools\n",
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, torch.nn.Conv2d):\n",
    "        zero_cnt = 0\n",
    "        out_channel = module.weight.shape[0]\n",
    "        in_channel = module.weight.shape[1]\n",
    "        kernel_size = module.weight.shape[2] * module.weight.shape[3]\n",
    "        for in_c in range(in_channel):\n",
    "            weight_sum = 0.0\n",
    "            for out_c in range(out_channel):\n",
    "                weight_sum += torch.sum(module.weight[out_c, in_c])\n",
    "            if weight_sum == 0:\n",
    "                # print(name, \"all zero weights channel\", in_c)\n",
    "                zero_cnt += 1\n",
    "        print(name, \"all zero weights \", zero_cnt, \"/\", in_channel)\n",
    "    elif isinstance(module, torch.nn.Linear):\n",
    "        zero_cnt = 0\n",
    "        out_channel = module.weight.shape[0]\n",
    "        in_channel = module.weight.shape[1]\n",
    "        for in_c in range(in_channel):\n",
    "            weight_sum = 0.0\n",
    "            for out_c in range(out_channel):\n",
    "                weight_sum += torch.sum(module.weight[out_c, in_c])\n",
    "            if weight_sum == 0:\n",
    "                # print(name, \"all zero weights channel\", in_c)\n",
    "                zero_cnt += 1\n",
    "        print(name, \"all zero weights \", zero_cnt, \"/\", in_channel) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unstructured Pruning (ネットワーク全体)\n",
    "weight_name = \"./../1-classification_mnist/weight/MNIST_lenet_10.pth\"\n",
    "print(\"use pretrained model : %s\" % weight_name)\n",
    "param = torch.load(weight_name, map_location=lambda storage, loc: storage)\n",
    "model = LeNet()\n",
    "model.load_state_dict(param)\n",
    "\n",
    "parameters_to_prune = []\n",
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, torch.nn.Conv2d):\n",
    "        parameters_to_prune.append((module, 'weight'))\n",
    "    elif isinstance(module, torch.nn.Linear):\n",
    "        parameters_to_prune.append((module, 'weight'))\n",
    "parameters_to_prune = tuple(parameters_to_prune)\n",
    "\n",
    "print(parameters_to_prune)\n",
    "prune_amount = 0.4\n",
    "# ネットワーク全体でL1normが小さい順に20%枝刈り \n",
    "prune.global_unstructured(\n",
    "    parameters_to_prune,\n",
    "    pruning_method=prune.L1Unstructured,\n",
    "    amount=prune_amount,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sparsity in features[0].weight: {:.2f}%\".format(\n",
    "        100. * float(torch.sum(model.features[0].weight == 0))\n",
    "        / float(model.features[0].weight.nelement())))\n",
    "print(\"Sparsity in features[3].weight: {:.2f}%\".format(\n",
    "        100. * float(torch.sum(model.features[3].weight == 0))\n",
    "        / float(model.features[3].weight.nelement())))\n",
    "print(\"Sparsity in classifier[0].weight: {:.2f}%\".format(\n",
    "        100. * float(torch.sum(model.classifier[0].weight == 0))\n",
    "        / float(model.classifier[0].weight.nelement())))\n",
    "print(\"Sparsity in classifier[2].weight: {:.2f}%\".format(\n",
    "        100. * float(torch.sum(model.classifier[2].weight == 0))\n",
    "        / float(model.classifier[2].weight.nelement())))\n",
    "print(\"Sparsity in classifier[4].weight: {:.2f}%\".format(\n",
    "        100. * float(torch.sum(model.classifier[4].weight == 0))\n",
    "        / float(model.classifier[4].weight.nelement())))\n",
    "\n",
    "print(\"Global sparsity: {:.2f}%\".format(\n",
    "        100. * float(torch.sum(model.features[0].weight == 0)\n",
    "            + torch.sum(model.features[3].weight == 0)\n",
    "            + torch.sum(model.classifier[0].weight == 0)\n",
    "            + torch.sum(model.classifier[2].weight == 0)\n",
    "            + torch.sum(model.classifier[4].weight == 0))\n",
    "        / float(model.features[0].weight.nelement()\n",
    "            + model.features[3].weight.nelement()\n",
    "            + model.classifier[0].weight.nelement()\n",
    "            + model.classifier[2].weight.nelement()\n",
    "            + model.classifier[4].weight.nelement())))\n",
    "\n",
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, torch.nn.Conv2d):\n",
    "        prune.remove(module, 'weight')\n",
    "    elif isinstance(module, torch.nn.Linear):\n",
    "        prune.remove(module, 'weight')\n",
    "torch.save(model.state_dict(), 'weight/MNIST_lenet_10_unstructured_pruning.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "精度のみの比較  \n",
    "cd ./../1-classification_mnist  \n",
    "python py/main.py --evaluate --resume='weight/MNIST_lenet_10.pth'  \n",
    "python py/main.py --evaluate --resume='./../notebook/weight/MNIST_lenet_10_unstructured_pruning.pth'  \n",
    "python py/main.py --evaluate --resume='./../notebook/weight/MNIST_lenet_10_structured_pruning.pth'  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use pretrained model : weight/MNIST_lenet_10.pth  \n",
    "Validate: [10/10] Loss 0.03638 (0.03311)  Acc@1  98.80 ( 98.92)   Acc@5 100.00 ( 99.99)   \n",
    "use pretrained model : ./../notebook/weight/MNIST_lenet_10_unstructured_pruning.pth  \n",
    "Validate: [10/10] Loss 0.03372 (0.03378)  Acc@1  98.90 ( 98.94)   Acc@5 100.00 ( 99.99)  \n",
    "use pretrained model : ./../notebook/weight/MNIST_lenet_10_structured_pruning.pth  \n",
    "Validate: [10/10] Loss 0.07547 (0.08172)  Acc@1  98.00 ( 97.52)   Acc@5 100.00 ( 99.99)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt14",
   "language": "python",
   "name": "pt14"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
